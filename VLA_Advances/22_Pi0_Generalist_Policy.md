# 22. π0 系列：通用机器人基座模型

## 1. Physical Intelligence 是谁？

**Physical Intelligence (π)** 是一家成立于 2024 年的机器人 AI 公司，由一群来自 Google DeepMind、Stanford、Berkeley 的顶级研究者创办。他们的目标极其明确：

> **"构建一个能控制任何机器人、完成任何物理任务的通用基座模型。"**

这就是 **π0 (Pi-Zero)**——目前最接近"通用机器人大脑"的模型。

## 2. π0：首个通用机器人策略（2024.10）

### (a) 核心目标

不同于 OpenVLA 等"多任务"模型（一个模型做 29 个任务），π0 追求的是真正的**通用性**：
*   控制**多种不同的机器人**（单臂、双臂、移动机器人）
*   执行**多种不同的任务**（抓取、折叠、装箱、清洁）
*   在**多种不同的环境**中工作

### (b) 训练数据

| 数据来源 | 规模 | 说明 |
| :--- | :--- | :--- |
| 真实机器人演示 | **10,000+ 小时** | 多种机器人平台 |
| 任务类型 | 数百种 | 抓取、放置、折叠、擦拭、装箱等 |
| 机器人类型 | 多种 | 单臂、双臂、灵巧手、移动底盘 |

这个数据规模远超之前所有工作（OpenVLA: 970K 条 ≈ ~2000 小时）。

### (c) 架构创新：VLM + 扩散动作头

π0 的架构与 OpenVLA 有一个根本不同：**用扩散模型替代自回归来生成动作**。

```
┌───────────────────────────────────────────────────────────┐
│                        π0 架构                            │
│                                                           │
│  [多视角图像] → ViT → 视觉 Token ─┐                       │
│  [语言指令]  → Tokenizer → 文本 Token ┤→ Pre-trained VLM   │
│  [本体感受]  → MLP → 本体 Token ────┘   (推理引擎)         │
│                                           ↓               │
│                                     Hidden State          │
│                                           ↓               │
│                                   🌊 Diffusion Head       │
│                                           ↓               │
│                                  Action Chunk (未来 N 步)  │
└───────────────────────────────────────────────────────────┘
```

**为什么选扩散而非自回归？**

| 需求 | 自回归 | 扩散 |
| :--- | :--- | :--- |
| 折叠衣服（精细操作） | 精度不够，动作抖动 | ✅ 连续值，平滑轨迹 |
| 从左或右绕过障碍 | 取平均 → 撞上去 | ✅ 采样一种方案，完整执行 |
| 一次规划长序列 | 逐 Token 太慢 | ✅ 一次去噪整段 Chunk |

### (d) 训练流程

**Stage 1: VLM 预训练**
*   基于一个大规模 VLM 初始化骨干网络（具备视觉-语言理解能力）。

**Stage 2: 跨任务/跨机器人混合训练**
*   在多种机器人、多种任务的海量数据上混合训练。
*   关键：**数据混合比例 (Data Mixing Ratio)** 的精心调配——不同机器人和任务的数据需要合理平衡。

**Stage 3: 任务特定微调（可选）**
*   对特别困难或需要极高精度的任务，可以进一步微调。

### (e) 核心能力

π0 展示了前所未有的通用操作能力：

| 能力 | 举例 |
| :--- | :--- |
| **灵巧操作** | 折叠衣服、擦桌子、装箱打包 |
| **双臂协作** | 两只手臂协同折叠大块织物 |
| **工具使用** | 使用清洁工具擦拭表面 |
| **长程任务** | 完成"整理桌面"这样需要多步骤的任务 |
| **语言指令** | 理解并遵循自然语言指令 |

---

## 3. π0-FAST：高效自回归变体（2025.01）

### (a) 动机

π0 的扩散头虽然精度高，但推理速度慢（需要多步去噪）。能否在保持性能的同时大幅提速？

### (b) FAST 编码

π0-FAST 用 **FAST (Frequency-space Action Sequence Tokenization)** 替代扩散头：

```
π0 (扩散版):
  VLM → Hidden State → 🌊 Diffusion (10 步去噪) → Action Chunk
                                     ↑ 慢

π0-FAST (自回归版):
  VLM → Hidden State → FAST Token 序列 (自回归生成 ~20 个 Token) → DCT 逆变换 → Action Chunk
                                     ↑ 快 5 倍
```

### (c) 关键成果

| 指标 | π0 (Diffusion) | π0-FAST |
| :--- | :--- | :--- |
| 性能 | 基线 | **持平** |
| 训练时间 | 基线 | **5 倍加速** |
| 推理方式 | 10 步扩散去噪 | ~20 个 Token 自回归 |
| 部署友好 | 需要扩散推理库 | 标准 LLM 推理框架 |

### (d) FAST+ 通用 Tokenizer

Physical Intelligence 还训练了 **FAST+**——一个在 **100 万条真实机器人轨迹**上预训练的通用动作 Tokenizer。它可以直接用于各种不同的机器人和动作空间，无需重新训练 Tokenizer。

---

## 4. π0.5：开放世界泛化（2025.04）

### (a) 核心突破

π0.5 解决了机器人 AI 最核心的挑战：**在从未见过的环境中工作**。

之前所有的 VLA 模型（包括 π0）都有一个共同问题：
*   在训练环境（如 Google 厨房）中表现很好。
*   换到一个新厨房（不同的台面、不同的物品摆放、不同的光照），性能就大幅下降。

π0.5 **首次实现了有意义的开放世界泛化**——把机器人送到**完全陌生的家庭环境**中，无需任何额外训练，就能完成复杂的长程任务。

### (b) 关键技术：知识隔离 + 混合训练

**知识隔离 (Knowledge Insulation)**：
*   防止不同数据源之间的知识冲突。
*   例如：A 机器人的数据教模型"桌子是木头的"，B 家庭的桌子是玻璃的 → 需要隔离这种环境特定知识，保留通用操作知识。

**异构数据混合训练 (Heterogeneous Co-Training)**：
*   混合以下数据：
    *   多种机器人的操作数据
    *   互联网上的语义知识（来自 VLM 预训练）
    *   语义预测数据（场景理解、物体检测）
*   不同数据源的学习信号被精心平衡，避免某一类数据"淹没"其他。

### (c) 实际展示

π0.5 被部署到**从未见过的真实家庭**中执行长程任务：

| 任务 | 描述 | 难点 |
| :--- | :--- | :--- |
| **清洁厨房** | 擦桌子、收拾餐具、关抽屉 | 10+ 步骤的长程任务，全新环境 |
| **整理卧室** | 叠被子、摆放枕头、整理物品 | 未见过的家具、布料形状各异 |
| **清理桌面** | 把各种物品放到正确位置 | 未见过的物品和空间布局 |

这些任务在训练时**从未出现过**——模型纯靠泛化完成。

### (d) 为什么这是里程碑？

| 之前的 VLA | π0.5 |
| :--- | :--- |
| 在实验室 A 训练 → 在实验室 A 工作 | 在多个环境训练 → 在**任何**家庭工作 |
| 换环境 = 重新训练 | 零样本适应新环境 |
| "我见过这个场景" | "我理解这种场景" |

---

## 5. π0 系列开源

Physical Intelligence 在 2025 年陆续开源了部分模型：

| 模型 | 开源状态 | 链接 |
| :--- | :--- | :--- |
| π0 | ✅ 权重 + 代码 | github.com/Physical-Intelligence/openpi |
| π0-FAST | ✅ 权重 + 代码 | 同上 |
| π0.5 | 部分开源 | — |

## 6. π0 系列时间线

```
2024.10  π0 发布        ← 首个通用机器人基座模型，10000+ 小时数据
2025.01  FAST 发布      ← 频域动作编码，自回归替代扩散，5x 加速
2025.01  π0-FAST 发布   ← π0 的高效自回归版本
2025.04  π0.5 发布      ← 🔑 首次开放世界泛化，全新家庭环境
2025.H1  OpenPi 开源    ← 社区可以复现和扩展
```

## 7. π0 vs OpenVLA vs RT-2

| 特性 | RT-2-X | OpenVLA | π0 / π0.5 |
| :--- | :--- | :--- | :--- |
| **参数量** | 55B | 7B | 未公开 (估计 ~3-7B) |
| **动作头** | 自回归 Binning | 自回归 Binning | **扩散 / FAST** |
| **数据规模** | ~数百小时 | ~2000 小时 | **10,000+ 小时** |
| **操作精度** | 中 | 中 | **高 (扩散)** |
| **泛化能力** | 有限 | 中 | **开放世界 (π0.5)** |
| **双臂支持** | ❌ | ❌ | **✅** |
| **灵巧操作** | 有限 | 有限 | **折叠、擦拭等** |
| **开源** | ❌ | ✅ | ✅ (部分) |

> **一句话总结**：π0 系列是目前最接近"通用机器人大脑"的模型——π0 用扩散策略实现了多机器人多任务控制，π0-FAST 用频域编码将速度提升 5 倍，π0.5 则首次将机器人从实验室带入了真实家庭。它代表了 VLA 从"实验室 demo"到"真实世界部署"的关键一步。
